{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d504e06-fc93-4f88-bf90-32dd24fa08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a8214e-9049-4f35-acfd-28d7a0fa0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c66ab8-758a-47e0-80de-3a7c42313f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils imported\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73a73e0-b001-45c0-80d4-f684c940685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relevant data\n",
    "associations = pd.read_csv('associations_rich.csv')\n",
    "hours = pd.read_csv('hours_rich.csv')\n",
    "incidences = pd.read_csv('incidences_rich.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cec99dd-20ad-4015-bc89-89f56610b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " that all of our sample data is loaded, we can begin our analysis.\n",
    " Lets begin with a timeline of the planned and effective\n",
    " allocation of all workers.\n",
    "'''\n",
    "\n",
    "# Join hours and associations to determine whether or not\n",
    "# the planned hours occured in the worker's original workplace.\n",
    "\n",
    "hours_associations = pd.merge(hours, associations, how='left',on='person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "831cfa52-eba7-4fdf-b667-5c78cbbf5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_associations = hours_associations[(hours_associations['day'] >= hours_associations['from_date']) & (hours_associations['day'] < hours_associations['to_date'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812d323f-9a9a-4204-aacb-7015cb049e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_associations = pd.merge(hours, hours_associations, how='left', on=['day', 'person_id', 'hour'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41692294-ceaa-4ece-807d-71032ee4e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_cal = hours_associations.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0af0ddf-dd0f-40db-b0a5-9ae205715837",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_cal['planned_hours'] = work_cal.groupby(['day','person_id'])['worked_hours_x'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d441e48-e52e-4447-85f7-c38c9576df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_cal = work_cal[['day','person_id','planned_hours','store_id']].sort_values(by=['person_id','day']).drop_duplicates(subset=['day','person_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6263f72-5563-4671-b505-013b866e636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_cal['store_id'] = work_cal['store_id'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c9c43b-4026-49f8-943c-7de8f7fcf437",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_cal['in_alternate_workplace'] = work_cal.apply(lambda x: True if x['store_id'] != '' else False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75d6f040-031e-49a6-908a-4cc7bdb83ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " At this stage we have the planned allocation per day and workplace.\n",
    " We need to cross reference against worker absences to verify that\n",
    " they did indeed work.\n",
    "'''\n",
    "\n",
    "work_cal_incidences = pd.merge(work_cal, incidences_raw, how='left', on='person_id')\n",
    "work_cal_incidences = work_cal_incidences[(work_cal_incidences['day'] >= work_cal_incidences['from_date']) & (work_cal_incidences['day'] < work_cal_incidences['to_date'])]\n",
    "work_cal_incidences = pd.merge(work_cal, work_cal_incidences[['day','person_id','type_name']], how='left', on=['day','person_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb176551-b5bf-42c8-8d72-293e6ecf2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_cal_incidences['type_name'] = work_cal_incidences['type_name'].fillna('')\n",
    "work_cal_incidences['was_absent'] = work_cal_incidences.apply(lambda x: False if x['type_name'] == '' else True, axis=1)\n",
    "work_cal_incidences['worked_hours'] = work_cal_incidences.apply(lambda x: x['planned_hours'] if x['was_absent'] == False else 0, axis=1)\n",
    "work_cal_incidences.rename(columns={'type_name':'absence_type'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96d31fe9-c32b-4b1e-ae12-9f69d0e4ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_cal_incidences.sort_values(by=['day','person_id']).to_csv('work_cal_incidences.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8c22f-47bf-4c9b-b220-23b9fe82f470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df92caa-6208-4fe9-8c95-efe6ad56d14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
